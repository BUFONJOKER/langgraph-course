# ğŸš€ LangGraph Course

Welcome to the LangGraph Course repository! This project explores sequential workflows and advanced orchestration using LangGraph framework.

---

## ğŸ“ Project Structure

### ğŸ  Root Directory

The root directory contains essential project configuration and entry point files.

#### ğŸ“„ Files

- **`main.py`** ğŸ“: Main entry point script for the project
- **`main.ipynb`** ğŸ““: Jupyter Notebook for interactive exploration and testing
- **`pyproject.toml`** âš™ï¸: Python project configuration and dependency management
- **`README.md`** ğŸ“–: Project documentation (this file)
- **`uv.lock`** ğŸ”’: Dependency lock file for reproducible environments
- **`.python-version`** ğŸ: Python version specification for the project
- **`.env`** ğŸ”: Environment variables configuration (not tracked in git)
- **`.gitignore`** ğŸš«: Git ignore patterns for version control
- **`.git/`** ğŸ“š: Git repository metadata and history

#### ğŸ—‚ï¸ Directories

- **`f_01_sequential_workflows/`** âš™ï¸: Main module containing sequential workflow implementations

---

## ğŸ“¦ f_01_sequential_workflows

This folder contains the core implementation of sequential workflows using LangGraph.

### ğŸ“„ Root Module Files

- **`__init__.py`** ğŸ’«: Python package initialization file

### ğŸ“‚ Subfolders

#### 1ï¸âƒ£ sf_01_simple_workflow

A simple workflow demonstrating basic sequential operations with BMI (Body Mass Index) calculation.

**ğŸ“„ Files:**

- **`main.py`** ğŸ¯: Main workflow orchestration script
- **`bmi_calculate.py`** ğŸ§®: BMI calculation logic
- **`bmi_state_class.py`** ğŸ“Š: State management class for BMI workflow
- **`label_bmi.py`** ğŸ·ï¸: BMI classification and labeling logic
- **`graph.png`** ğŸ–¼ï¸: Visual representation of the workflow graph

---

#### 2ï¸âƒ£ sf_02_llm_based_workflows

LLM-based sequential workflows demonstrating question-answering systems with different model backends.

**ğŸ“„ Files:**

- **`main.py`** ğŸ¯: Main LLM workflow script
- **`main.ipynb`** ğŸ““: Interactive Jupyter Notebook for LLM workflows
- **`llm_question_answer.py`** ğŸ¤–: Question-answering implementation
- **`llm_state_class.py`** ğŸ“Š: State management class for LLM workflows
- **`model_huggingface.py`** ğŸ¤—: Hugging Face model integration
- **`model_ollama.py`** ğŸ¦™: Ollama model integration
- **`__init__.py`** ğŸ’«: Package initialization file

---

#### 3ï¸âƒ£ sf_03_prompt_chaining

Advanced prompt chaining workflows for blog generation with outline evaluation.

**ğŸ“„ Files:**

- **`main.py`** ğŸ¯: Main prompt chaining orchestration script
- **`main.ipynb`** ğŸ““: Interactive Jupyter Notebook for prompt chaining
- **`blog_state.py`** ğŸ“: State management class for blog generation workflow
- **`generate_outline.py`** ğŸ“‹: Outline generation logic
- **`generate_blog.py`** âœï¸: Blog post generation logic
- **`evaluation.py`** â­: Evaluation and validation of generated content
- **`model.py`** ğŸ”Œ: Model configuration and initialization
- **`__init__.py`** ğŸ’«: Package initialization file

---

## ğŸ¯ Key Features

### âœ¨ Sequential Workflows
- **Simple Workflows**: Basic workflow operations with BMI calculations
- **LLM Integration**: Integration with multiple LLM backends (Hugging Face, Ollama)
- **Prompt Chaining**: Advanced multi-step prompt chains for complex tasks like blog generation

### ğŸ”„ State Management
- Structured state classes for each workflow module
- Type-safe state transitions
- Efficient state handling across workflow steps

### ğŸ§  Model Support
- Hugging Face models integration
- Ollama local model support
- Flexible model configuration

---

## ğŸ› ï¸ Development Setup

### Requirements
- Python 3.x
- Virtual environment (`.venv/`)
- Dependencies specified in `pyproject.toml`

### Quick Start
1. Activate the virtual environment: `.venv/Scripts/Activate.ps1`
2. Run the main script: `python main.py`
3. Or explore with Jupyter: `jupyter notebook main.ipynb`

---

## ğŸ“š Workflow Modules

### Module 1: Simple Workflow
Calculate and classify BMI values through a sequential workflow.

### Module 2: LLM-Based Workflow
Ask questions to LLMs and receive answers from different model backends.

### Module 3: Prompt Chaining
Generate complete blog posts by chaining multiple prompts together with evaluation.

---

## ğŸ”§ Configuration

- **`pyproject.toml`**: Manage project dependencies and metadata
- **`.env`**: Set environment variables and API keys
- **`.python-version`**: Specify Python version requirement

---

## ğŸ“” Interactive Notebooks

Explore the workflows interactively using Jupyter Notebooks:
- `main.ipynb` (Root level)
- `sf_02_llm_based_workflows/main.ipynb`
- `sf_03_prompt_chaining/main.ipynb`

---

## ğŸš€ Getting Started

To get started with this LangGraph course:

1. **Set up environment**: Install dependencies from `pyproject.toml`
2. **Explore examples**: Start with `sf_01_simple_workflow` for basic concepts
3. **Try LLM integration**: Move to `sf_02_llm_based_workflows` for model usage
4. **Master prompt chaining**: Finish with `sf_03_prompt_chaining` for advanced techniques

---

**Happy Learning! ğŸ“**
